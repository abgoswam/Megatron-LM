{
    "name": "phi3-cp-trial-4gpus",
    "type": "debugpy",
    "request": "launch",
    "program": "/usr/local/bin/torchrun",
    // "module": "torch.distributed.run",
    // "program": "${workspaceFolder}/pretrain_gpt.py",
    "justMyCode": false,
    "console": "integratedTerminal",
    "env": {
        "CUDA_DEVICE_MAX_CONNECTIONS": "1",
        "CUDA_VISIBLE_DEVICES": "0,1,2,3",
    },
    "args": [
        "--standalone",
        "--nproc_per_node=4",
        "--nnodes=1",
        "--node_rank=0",
        "--master_port=9500",
        "--master_addr=node-0",
        "${workspaceFolder}/pretrain_gpt.py",
        "--tensor-model-parallel-size",
        "1",
        "--sequence-parallel",
        "--use-flash-attn",
        "--transformer-impl",
        "local",
        "--num-layers",
        "32",
        "--hidden-size",
        "3072",
        "--ffn-hidden-size",
        "8192",
        "--swiglu",
        "--num-attention-heads",
        "32",
        "--seq-length",
        "4096",
        "--max-position-embeddings",
        "4096",
        // "--vocab-size",
        // "32000",
        // "--make-vocab-size-divisible-by",
        // "64",
        // "--tokenizer-type",
        // "Llama2Tokenizer",
        // "--tokenizer-model", "extras/phi3-tokenizer/tokenizer.model",
        "--make-vocab-size-divisible-by", "64",
        "--tokenizer-type",
        // "Llama2Tokenizer",
        "HuggingFaceTokenizer",
        "--tokenizer-model", "/mnt/posttraining/ckpts/Phi-3-mini-4k-instruct",
        // "--tokenizer-model", "/mnt/posttraining/ckpts/Phi-3-mini-4k-instruct/tokenizer.model",
        "--micro-batch-size",
        "1",
        "--global-batch-size",
        "4",
        "--lr",
        "0.00015",
        "--train-iters",
        "100",
        "--lr-decay-iters",
        "20",
        "--lr-decay-style",
        "cosine",
        "--min-lr",
        "1.0e-5",
        "--weight-decay",
        "1e-2",
        "--lr-warmup-fraction",
        ".01",
        "--clip-grad",
        "1.0",
        "--bf16",
        "--data-path",
        "extras/train_data_phi3/phi3_text_document",
        "--split",
        "949,50,1",
        "--log-interval",
        "10",
        "--save-interval",
        "10",
        "--eval-interval",
        "10",
        "--eval-iters",
        "10",
        "--save",
        "extras/ckpts",
        "--load", "/home/aiscuser/tmp/phi3.1_mcore_converted_without_posemb-throw/",
        "--use-distributed-optimizer",
        "--no-load-optim",
        "--no-load-rng",
        "--untie-embeddings-and-output-weights",
        // "--load", "/mnt/posttraining/sambroy/pretraining/checkpoints/phi3-megatron-iter200",
    ],
},